#!/usr/bin/env python3
"""
ç¿»è¯‘æµç¨‹æ¨¡å— - åŒ…å«ä¸»å‡½æ•°å’Œç¿»è¯‘æµç¨‹æ§åˆ¶é€»è¾‘
"""

import os
import sys
from typing import Dict, List, Tuple
from pathlib import Path

from .config import get_all_target_languages
from .logging import log_progress, log_section, log_section_end, ProgressTracker, flush_logs
from .translator import DeepSeekTranslator
from .git_changes import get_git_changes
from .file_ops import (
    get_namespace_list,
    load_namespace_translations_from_translate,
    save_namespace_translations,
    get_merged_reference_translations,
    get_context_for_keys,
    load_json_file,
    save_json_file
)
from .config import KeyChange, FileChanges, ChangeType


def needs_translation(namespace: str, lang_code: str, source_dict: Dict[str, str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘"""
    force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'

    if force_translate:
        return True

    # æ£€æŸ¥å·²æœ‰ç¿»è¯‘æ˜¯å¦å®Œæ•´ï¼ˆä»…æ£€æŸ¥translateç›®å½•ï¼‰
    existing_translations = load_namespace_translations_from_translate(namespace, lang_code)

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç¿»è¯‘ï¼Œéœ€è¦ç¿»è¯‘
    if not existing_translations:
        return True

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é”®éœ€è¦ç¿»è¯‘
    missing_keys = set(source_dict.keys()) - set(existing_translations.keys())
    if missing_keys:
        log_progress(f"{lang_code}: å‘ç° {len(missing_keys)} ä¸ªæ–°é”®éœ€è¦ç¿»è¯‘")
        return True

    return False


def check_missing_translation_files() -> List[Tuple[str, str]]:
    """æ£€æŸ¥ç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶

    Returns:
        List[Tuple[str, str]]: ç¼ºå¤±æ–‡ä»¶çš„ (namespace, lang_code) åˆ—è¡¨
    """
    missing_files = []

    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    namespaces = get_namespace_list()

    for namespace in namespaces:
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»»ä½•è¯­è¨€æ–‡ä»¶
        namespace_lang_dir = Path("subprojects/Localization-Resource-Pack/assets") / namespace / "lang"
        if not namespace_lang_dir.exists():
            continue

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•è¯­è¨€æ–‡ä»¶å­˜åœ¨
        has_lang_files = any(f.suffix == '.json' for f in namespace_lang_dir.glob('*.json'))
        if not has_lang_files:
            continue

        # æ£€æŸ¥æ¯ç§ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘æ–‡ä»¶
        for lang_code, _ in get_all_target_languages().items():
            translate_file = Path("translate") / namespace / "lang" / f"{lang_code}.json"
            if not translate_file.exists():
                missing_files.append((namespace, lang_code))

    if missing_files:
        log_progress(f"å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶")
        for namespace, lang_code in missing_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            log_progress(f"  ç¼ºå¤±: {namespace}/{lang_code}.json")
        if len(missing_files) > 5:
            log_progress(f"  ... è¿˜æœ‰ {len(missing_files) - 5} ä¸ªæ–‡ä»¶")

    return missing_files


def create_virtual_changes_for_missing_files(missing_files: List[Tuple[str, str]]) -> List[FileChanges]:
    """ä¸ºç¼ºå¤±çš„ç¿»è¯‘æ–‡ä»¶åˆ›å»ºè™šæ‹Ÿå˜æ›´

    Args:
        missing_files: ç¼ºå¤±æ–‡ä»¶çš„ (namespace, lang_code) åˆ—è¡¨

    Returns:
        List[FileChanges]: è™šæ‹Ÿå˜æ›´åˆ—è¡¨
    """
    # æŒ‰å‘½åç©ºé—´åˆ†ç»„
    namespace_groups = {}
    for namespace, lang_code in missing_files:
        if namespace not in namespace_groups:
            namespace_groups[namespace] = []
        namespace_groups[namespace].append(lang_code)

    virtual_changes = []

    for namespace, lang_codes in namespace_groups.items():
        # ä½¿ç”¨åˆå¹¶åçš„å‚è€ƒç¿»è¯‘ä»¥è·å–æ‰€æœ‰é”®
        source_dict = get_merged_reference_translations(namespace)
        if not source_dict:
            continue

        # ä¸ºæ¯ä¸ªç¼ºå¤±çš„è¯­è¨€æ–‡ä»¶åˆ›å»ºè™šæ‹Ÿå˜æ›´
        for lang_code in lang_codes:
            # åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼Œå°†æ‰€æœ‰åˆå¹¶åçš„é”®æ ‡è®°ä¸ºæ–°å¢
            added_keys = []
            for key, value in source_dict.items():
                # å¤„ç†åˆ—è¡¨å€¼çš„æƒ…å†µ
                if isinstance(value, list):
                    # å¯¹äºåˆ—è¡¨å€¼ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºç¿»è¯‘æº
                    added_keys.append(KeyChange(key=key, old_value=None, new_value=value[0], operation='added'))
                else:
                    added_keys.append(KeyChange(key=key, old_value=None, new_value=value, operation='added'))

            # æ„å»ºç¼ºå¤±æ–‡ä»¶çš„è·¯å¾„
            missing_file_path = f"{namespace}/{lang_code}.json"

            virtual_changes.append(FileChanges(
                namespace=namespace,
                file_path=missing_file_path,
                added_keys=added_keys,
                deleted_keys=[],
                modified_keys=[]
            ))

        log_progress(f"ä¸ºå‘½åç©ºé—´ {namespace} åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼ŒåŒ…å« {len(added_keys)} ä¸ªé”®")

    return virtual_changes


def create_virtual_changes_for_missing_keys() -> List[FileChanges]:
    """ä¸ºå·²æœ‰ç¿»è¯‘æ–‡ä»¶ä¸­çš„ç¼ºå¤±é”®åˆ›å»ºè™šæ‹Ÿå˜æ›´ï¼Œåªæ‰«æç¼ºå¤±é”®ï¼Œå¿½ç•¥è¾“å‡ºç›®å½•çš„ä¿®æ”¹"""
    virtual_changes: List[FileChanges] = []

    # éå†æ‰€æœ‰å‘½åç©ºé—´
    for namespace in get_namespace_list():
        # ä½¿ç”¨åˆå¹¶åçš„å‚è€ƒç¿»è¯‘è·å–å®Œæ•´é”®é›†åˆ
        source_dict = get_merged_reference_translations(namespace)
        if not source_dict:
            continue

        source_keys = list(source_dict.keys())

        # éå†æ‰€æœ‰ç›®æ ‡è¯­è¨€
        for lang_code, _ in get_all_target_languages().items():
            translate_file = Path("translate") / namespace / "lang" / f"{lang_code}.json"
            if not translate_file.exists():
                # æ–‡ä»¶ç¼ºå¤±çš„åœºæ™¯ç”± create_virtual_changes_for_missing_files å¤„ç†
                continue

            # ä»…åŸºäº translate ç›®å½•æ£€æŸ¥ç¼ºå¤±ï¼Œassets å°†åœ¨æ„å»ºæ—¶åˆå¹¶
            existing_translations = load_namespace_translations_from_translate(namespace, lang_code)
            existing_keys = set(existing_translations.keys())

            # ä»…æ‰«æç¼ºå¤±é”®ï¼ˆå¿½ç•¥è¾“å‡ºç›®å½•çš„ä¿®æ”¹ï¼‰
            missing_keys = [k for k in source_keys if k not in existing_keys]
            if not missing_keys:
                continue

            added_keys: List[KeyChange] = []
            for key in missing_keys:
                value = source_dict.get(key)
                if isinstance(value, list):
                    value = value[0] if value else ""
                added_keys.append(KeyChange(key=key, old_value=None, new_value=value, operation=ChangeType.ADDED.value))

            virtual_changes.append(FileChanges(
                namespace=namespace,
                file_path=f"{namespace}/{lang_code}.json",
                added_keys=added_keys,
                deleted_keys=[],
                modified_keys=[]
            ))

            log_progress(f"ä¸ºå‘½åç©ºé—´ {namespace} -> {lang_code} åˆ›å»ºç¼ºå¤±é”®è¡¥å…¨ä»»åŠ¡ï¼š{len(added_keys)} ä¸ªé”®")

    return virtual_changes


def delete_keys_from_translations(namespace: str, keys_to_delete: List[str]) -> bool:
    """ä»æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶ä¸­åˆ é™¤æŒ‡å®šçš„é”®"""
    success = True

    # å¤„ç†æ‰€æœ‰ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘æ–‡ä»¶
    for lang_code, _ in get_all_target_languages().items():
        translate_file = Path("translate") / namespace / "lang" / f"{lang_code}.json"
        if not translate_file.exists():
            continue

        # åŠ è½½ç°æœ‰ç¿»è¯‘
        translations = load_json_file(str(translate_file))
        if not translations:
            continue

        # åˆ é™¤æŒ‡å®šçš„é”®
        modified = False
        for key in keys_to_delete:
            if key in translations:
                del translations[key]
                modified = True

        # å¦‚æœæœ‰ä¿®æ”¹ï¼Œä¿å­˜æ–‡ä»¶
        if modified:
            if save_json_file(str(translate_file), translations):
                log_progress(f"    âœ“ ä» {lang_code} ç¿»è¯‘ä¸­åˆ é™¤äº† {len([k for k in keys_to_delete if k in translations])} ä¸ªé”®")
            else:
                log_progress(f"    âœ— åˆ é™¤é”®å¤±è´¥: {translate_file}", "error")
                success = False

    return success


def perform_cleanup_extra_keys():
    """æ¸…ç†æ‰€æœ‰å‘½åç©ºé—´ä¸è¯­è¨€ä¸­çš„å¤šä½™é”®ï¼Œå¹¶ä¿å­˜æ›´æ–°"""
    # æ¸…ç†å¤šä½™çš„é”®å€¼å¯¹
    log_progress("å¼€å§‹æ¸…ç†å¤šä½™çš„é”®å€¼å¯¹...")
    cleaned_count = 0
    total_keys_removed = 0

    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    all_namespaces = get_namespace_list()
    log_progress(f"å¤„ç†çš„å‘½åç©ºé—´: {', '.join(all_namespaces)}")

    for namespace in all_namespaces:
        # è·å–æºå­—å…¸ï¼ˆå‚è€ƒç¿»è¯‘ï¼‰
        source_dict = get_merged_reference_translations(namespace)
        if not source_dict:
            log_progress(f"âš ï¸ å‘½åç©ºé—´ {namespace} æ²¡æœ‰æºå­—å…¸", "warning")
            continue

        log_progress(f"å‘½åç©ºé—´ {namespace} æºå­—å…¸åŒ…å« {len(source_dict)} ä¸ªé”®")

        # è·å–æ‰€æœ‰ç›®æ ‡è¯­è¨€
        for lang_code, lang_name in get_all_target_languages().items():
            # åŠ è½½ç°æœ‰ç¿»è¯‘ï¼ˆä»…æ£€æŸ¥ translate ç›®å½•ï¼›assets åœ¨æ„å»ºæ—¶åˆå¹¶ï¼Œä¸å‚ä¸å®Œæ•´æ€§æ£€æŸ¥ï¼‰
            existing_translations = load_namespace_translations_from_translate(namespace, lang_code)
            if not existing_translations:
                log_progress(f"âš ï¸ æœªåœ¨ translate ç›®å½•æ‰¾åˆ°ç¿»è¯‘æ–‡ä»¶: {namespace} -> {lang_code}", "warning")
                continue

            log_progress(f"æ£€æŸ¥ {namespace} -> {lang_code}: åŒ…å« {len(existing_translations)} ä¸ªé”®")

            # æ‰¾å‡ºå¤šä½™çš„é”®ï¼ˆåœ¨ç¿»è¯‘ä¸­å­˜åœ¨ä½†åœ¨æºå­—å…¸ä¸­ä¸å­˜åœ¨çš„é”®ï¼‰
            source_keys = set(source_dict.keys())
            keys_to_remove = [key for key in existing_translations if key not in source_keys]

            if keys_to_remove:
                log_progress(f"å‘ç° {len(keys_to_remove)} ä¸ªå¤šä½™é”®: {', '.join(keys_to_remove[:5])}{' ç­‰' if len(keys_to_remove) > 5 else ''}")

                # ç§»é™¤å¤šä½™çš„é”®
                for key in keys_to_remove:
                    del existing_translations[key]

                # ä¿å­˜æ›´æ–°åçš„ç¿»è¯‘ï¼ˆä¿å­˜åˆ° translate ç›®å½•ï¼‰
                try:
                    if save_namespace_translations(namespace, lang_code, existing_translations):
                        cleaned_count += 1
                        total_keys_removed += len(keys_to_remove)
                        log_progress(f"âœ“ æ¸…ç† {namespace} -> {lang_code}: ç§»é™¤äº† {len(keys_to_remove)} ä¸ªå¤šä½™é”®", "info")
                    else:
                        log_progress(f"âœ— æ¸…ç†å¤±è´¥: {namespace} -> {lang_code}", "error")
                except Exception as e:
                    log_progress(f"âœ— æ¸…ç†æ—¶å‘ç”Ÿé”™è¯¯: {namespace} -> {lang_code}, é”™è¯¯: {str(e)}", "error")
            else:
                log_progress(f"âœ“ {namespace} -> {lang_code}: æ²¡æœ‰å¤šä½™é”®", "info")

    log_progress(f"æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç†äº† {cleaned_count} ä¸ªæ–‡ä»¶ï¼Œç§»é™¤äº† {total_keys_removed} ä¸ªå¤šä½™é”®")


def continue_full_translation(translator, progress_tracker, namespaces):
    """ç»§ç»­æ‰§è¡Œå…¨é‡ç¿»è¯‘çš„å‰©ä½™é€»è¾‘ - å…¨å¹¶å‘ç‰ˆæœ¬"""
    log_progress("å¼€å§‹å‡†å¤‡æ‰€æœ‰ç¿»è¯‘è¯·æ±‚...")

    # ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„å†…å®¹
    all_translation_tasks = []
    force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'

    for namespace in namespaces:
        # ä½¿ç”¨åˆå¹¶åçš„å‚è€ƒç¿»è¯‘
        source_dict = get_merged_reference_translations(namespace)
        if not source_dict:
            log_progress(f"è·³è¿‡å‘½åç©ºé—´ {namespace}ï¼šæ— æ³•åŠ è½½åˆå¹¶å‚è€ƒç¿»è¯‘", "warning")
            continue

        log_progress(f"âœ“ å‘½åç©ºé—´ {namespace}ï¼š{len(source_dict)} ä¸ªé”®å€¼å¯¹")

        for lang_code, lang_name in get_all_target_languages().items():
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘
            if not needs_translation(namespace, lang_code, source_dict):
                continue

            # åŠ è½½å·²æœ‰ç¿»è¯‘ï¼ˆä»…ä»translateç›®å½•ï¼‰
            existing_translate = load_namespace_translations_from_translate(namespace, lang_code)

            # ç¡®å®šéœ€è¦ç¿»è¯‘çš„å†…å®¹
            if force_translate:
                keys_to_translate = source_dict.copy()
            else:
                keys_to_translate = {k: v for k, v in source_dict.items() if k not in existing_translate}

            if keys_to_translate:
                all_translation_tasks.append({
                    'namespace': namespace,
                    'lang_code': lang_code,
                    'lang_name': lang_name,
                    'texts': keys_to_translate,
                    'existing_translations': existing_translate
                })

    if not all_translation_tasks:
        log_progress("æ‰€æœ‰å†…å®¹å·²ç¿»è¯‘å®Œæˆ")
        return

    log_progress(f"âœ“ å‡†å¤‡å®Œæˆï¼š{len(all_translation_tasks)} ä¸ªç¿»è¯‘ä»»åŠ¡")

    # ç¬¬äºŒé˜¶æ®µï¼šå‡†å¤‡æ‰€æœ‰ç¿»è¯‘è¯·æ±‚
    log_progress("å‡†å¤‡ç¿»è¯‘è¯·æ±‚...")
    all_requests = []

    for task in all_translation_tasks:
        prepared_texts = translator.prepare_texts_for_translation(task['texts'])
        target_languages = [(task['lang_code'], task['lang_name'])]

        # åˆ›å»ºç¿»è¯‘è¯·æ±‚
        requests = translator.prepare_translation_requests(prepared_texts, target_languages, batch_size=40, namespace=task['namespace'])

        # ä¸ºæ¯ä¸ªè¯·æ±‚æ·»åŠ ä»»åŠ¡ä¿¡æ¯
        for request in requests:
            request.namespace = task['namespace']
            request.existing_translations = task['existing_translations']
            all_requests.append(request)

    log_progress(f"âœ“ ç”Ÿæˆäº† {len(all_requests)} ä¸ªç¿»è¯‘è¯·æ±‚")

    # ç¬¬ä¸‰é˜¶æ®µï¼šä¸€æ¬¡æ€§å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
    log_progress("å¼€å§‹å…¨å¹¶å‘ç¿»è¯‘...")
    results_by_namespace_and_language = translator.execute_requests_concurrently(all_requests)

    # ç¬¬å››é˜¶æ®µï¼šä¿å­˜ç¿»è¯‘ç»“æœ
    log_progress("ä¿å­˜ç¿»è¯‘ç»“æœ...")
    saved_count = 0

    for task in all_translation_tasks:
        namespace = task['namespace']
        lang_code = task['lang_code']
        existing_translations = task['existing_translations']

        # è·å–è¯¥ä»»åŠ¡çš„ç¿»è¯‘ç»“æœ
        if (namespace in results_by_namespace_and_language and
            lang_code in results_by_namespace_and_language[namespace]):
            translated_results = results_by_namespace_and_language[namespace][lang_code]

            # è®¡ç®—çœŸæ­£çš„æ–°ç¿»è¯‘æ•°é‡
            if force_translate:
                # å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šæ‰€æœ‰ç¿»è¯‘ç»“æœéƒ½æ˜¯æ–°çš„ï¼ˆè¦†ç›–ç°æœ‰ç¿»è¯‘ï¼‰
                final_translations = translated_results
                new_translations_count = len(translated_results)
            else:
                # å¢é‡ç¿»è¯‘æ¨¡å¼ï¼štranslated_resultsä¸­çš„æ‰€æœ‰é”®éƒ½æ˜¯æ–°çš„
                # ï¼ˆå› ä¸ºkeys_to_translateå·²ç»è¿‡æ»¤æ‰äº†existing_translationsä¸­å­˜åœ¨çš„é”®ï¼‰
                new_translations_count = len(translated_results)
                final_translations = existing_translations.copy()
                final_translations.update(translated_results)

            # ä¿å­˜ç¿»è¯‘ç»“æœ
            if save_namespace_translations(namespace, lang_code, final_translations):
                saved_count += 1
                log_progress(f"âœ“ {namespace} -> {lang_code}: {new_translations_count} ä¸ªæ–°ç¿»è¯‘")
            else:
                log_progress(f"âœ— ä¿å­˜å¤±è´¥: {namespace} -> {lang_code}", "error")
        else:
            log_progress(f"âœ— æœªæ‰¾åˆ°ç¿»è¯‘ç»“æœ: {namespace} -> {lang_code}", "warning")

    log_progress(f"ğŸ‰ å…¨å¹¶å‘ç¿»è¯‘å®Œæˆï¼æˆåŠŸä¿å­˜ {saved_count}/{len(all_translation_tasks)} ä¸ªç¿»è¯‘æ–‡ä»¶")

    # ç¿»è¯‘å®Œæˆåç»Ÿä¸€æ‰§è¡Œæ¸…ç†
    perform_cleanup_extra_keys()
    flush_logs()


def run_full_translation(translator):
    """è¿è¡Œå…¨é‡ç¿»è¯‘ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
    # è·å–æ‰€æœ‰å‘½åç©ºé—´
    log_progress("æ‰«æå‘½åç©ºé—´...")
    namespaces = get_namespace_list()
    if not namespaces:
        log_progress("é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•å‘½åç©ºé—´", "error")
        sys.exit(1)

    log_progress(f"âœ“ æ‰¾åˆ° {len(namespaces)} ä¸ªå‘½åç©ºé—´: {', '.join(namespaces)}")
    # è®¡ç®—éœ€è¦ç¿»è¯‘çš„è¯­è¨€æ•°
    target_lang_count = len(get_all_target_languages())
    log_progress(f"âœ“ ç›®æ ‡è¯­è¨€: {target_lang_count} ç§")

    # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
    progress_tracker = ProgressTracker(target_lang_count, len(namespaces))

    log_section_end()

    # è°ƒç”¨åŸæœ‰çš„ç¿»è¯‘é€»è¾‘
    continue_full_translation(translator, progress_tracker, namespaces)


def run_smart_translation(translator):
    """è¿è¡Œæ™ºèƒ½å·®å¼‚ç¿»è¯‘ï¼ˆä¸€æ¬¡æ€§å¹¶å‘ï¼›åŸºäºGitå·®å¼‚æ”¶é›†é”®åï¼‰"""
    # ä½¿ç”¨ Git æ”¶é›†æ¯ä¸ªæºç›®å½•è¯­è¨€æ–‡ä»¶çš„é”®çº§å·®å¼‚ï¼Œéšååœ¨åˆå¹¶æºæ–‡æœ¬ä¸Šå¤„ç†
    file_changes = get_git_changes()

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ç¼ºå¤±æƒ…å†µ
    missing_translations = check_missing_translation_files()

    if missing_translations:
        virtual_changes = create_virtual_changes_for_missing_files(missing_translations)
        file_changes.extend(virtual_changes)
        log_progress(f"ä¸º {len(missing_translations)} ä¸ªç¼ºå¤±æ–‡ä»¶åˆ›å»ºè¡¥å…¨ç¿»è¯‘ä»»åŠ¡")

    # å·²æœ‰ç¿»è¯‘æ–‡ä»¶çš„ç¼ºå¤±é”®è¡¥å…¨ä»»åŠ¡
    missing_key_changes = create_virtual_changes_for_missing_keys()
    if missing_key_changes:
        file_changes.extend(missing_key_changes)
        log_progress(f"ä¸ºå·²æœ‰ç¿»è¯‘æ–‡ä»¶åˆ›å»ºç¼ºå¤±é”®è¡¥å…¨ä»»åŠ¡ï¼š{len(missing_key_changes)} ä¸ªå˜æ›´")

    if not file_changes:
        log_progress("æœªæ£€æµ‹åˆ°å·®å¼‚æˆ–ç¼ºå¤±ï¼Œè·³è¿‡ç¿»è¯‘")
        perform_cleanup_extra_keys()
        return

    log_progress(f"æ£€æµ‹åˆ° {len(file_changes)} ä¸ªå˜æ›´ä»»åŠ¡")

    # æ³¨æ„ï¼šåˆ é™¤é”®åœ¨åç»­æ¸…ç†è¿‡ç¨‹ä¸­å¤„ç†ï¼Œè¿™é‡Œå¿½ç•¥åˆ é™¤é”®

    # æ”¶é›†æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡ï¼ˆä¸€æ¬¡æ€§å¹¶å‘ï¼‰
    all_translation_tasks = []
    for changes in file_changes:
        # ä½¿ç”¨åˆå¹¶åçš„å‚è€ƒç¿»è¯‘
        source_dict = get_merged_reference_translations(changes.namespace)
        if not source_dict:
            log_progress(f"æ— æ³•åŠ è½½å‘½åç©ºé—´ {changes.namespace} çš„åˆå¹¶å‚è€ƒç¿»è¯‘", "error")
            continue

        # ç›®æ ‡é”®é›†åˆï¼šæ–°å¢ + ä¿®æ”¹ï¼ˆå»é‡ä¿æŒé¡ºåºï¼‰
        keys_to_translate = list(dict.fromkeys([c.key for c in (changes.added_keys + changes.modified_keys)]))
        if not keys_to_translate:
            continue

        # ä¸Šä¸‹æ–‡ç­–ç•¥ï¼šè‹¥å°‘äº10æ¡åˆ™è¡¥é½ä¸Šä¸‹æ–‡åˆ°10æ¡ï¼›å¦åˆ™ä»…ç›®æ ‡é”®
        if len(keys_to_translate) < 10:
            context_dict = get_context_for_keys(source_dict, keys_to_translate, max_context=10, force_context=False)
            log_progress(f"å·®å¼‚ç¿»è¯‘ä¸Šä¸‹æ–‡è¡¥å……ï¼š{len(keys_to_translate)} ä¸ªç›®æ ‡é”® + {len(context_dict) - len(keys_to_translate)} ä¸ªä¸Šä¸‹æ–‡é”® = {len(context_dict)} ä¸ªé”®å€¼å¯¹")
        else:
            context_dict = {k: source_dict[k] for k in keys_to_translate if k in source_dict}
            log_progress(f"å·®å¼‚ç¿»è¯‘ï¼š{len(context_dict)} ä¸ªé”®å€¼å¯¹ï¼ˆæ— éœ€æ·»åŠ ä¸Šä¸‹æ–‡ï¼‰")

        # ç›®æ ‡è¯­è¨€åˆ—è¡¨ï¼šé»˜è®¤æ‰€æœ‰è¯­è¨€ï¼›è‹¥ä¸ºç¼ºå¤±æ–‡ä»¶çš„è™šæ‹Ÿå˜æ›´ï¼Œåˆ™é™åˆ¶åˆ°è¯¥è¯­è¨€
        target_languages = get_all_target_languages().copy()
        if "/" in changes.file_path and changes.file_path.endswith('.json'):
            file_name = Path(changes.file_path).name
            target_lang_code = file_name[:-5]
            if target_lang_code in target_languages:
                target_languages = {target_lang_code: target_languages[target_lang_code]}
                log_progress(f"  è™šæ‹Ÿå˜æ›´ï¼šåªç¿»è¯‘ç¼ºå¤±çš„è¯­è¨€ {target_languages[target_lang_code]} ({target_lang_code})")
            else:
                target_languages = {}
                log_progress(f"  æœªçŸ¥çš„è¯­è¨€ä»£ç : {target_lang_code}ï¼Œè·³è¿‡ç¿»è¯‘")

        for lang_code, lang_name in target_languages.items():
            existing_translations = load_namespace_translations_from_translate(changes.namespace, lang_code)
            all_translation_tasks.append({
                'namespace': changes.namespace,
                'lang_code': lang_code,
                'lang_name': lang_name,
                'context_dict': context_dict,
                'keys_to_translate': keys_to_translate,
                'existing_translations': existing_translations
            })

    if not all_translation_tasks:
        log_progress("æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„ç¿»è¯‘ä»»åŠ¡")
        perform_cleanup_extra_keys()
        return

    log_progress(f"å‡†å¤‡ {len(all_translation_tasks)} ä¸ªç¿»è¯‘ä»»åŠ¡ï¼ˆå…¨å±€å¹¶å‘ï¼‰")

    # ç»Ÿä¸€å‡†å¤‡ä¸å¹¶å‘è¯·æ±‚
    all_requests = []
    for task in all_translation_tasks:
        prepared_context = translator.prepare_texts_for_translation(task['context_dict'])
        target_languages_list = [(task['lang_code'], task['lang_name'])]
        requests = translator.prepare_translation_requests(prepared_context, target_languages_list, batch_size=40, silent=True)
        for request in requests:
            request.namespace = task['namespace']
            request.keys_to_translate = task['keys_to_translate']
            request.existing_translations = task['existing_translations']
            all_requests.append(request)

    log_progress(f"å¼€å§‹å¹¶å‘ç¿»è¯‘ {len(all_requests)} ä¸ªè¯·æ±‚...")
    results_by_namespace_and_language = translator.execute_requests_concurrently(all_requests)

    # ä¿å­˜ç»“æœ
    saved_count = 0
    for task in all_translation_tasks:
        ns = task['namespace']
        lang = task['lang_code']
        keys = task['keys_to_translate']
        existing = task['existing_translations']
        if ns in results_by_namespace_and_language and lang in results_by_namespace_and_language[ns]:
            translated = results_by_namespace_and_language[ns][lang]
            target_translations = {k: translated[k] for k in keys if k in translated}
            final = existing.copy()
            final.update(target_translations)
            if save_namespace_translations(ns, lang, final):
                saved_count += 1
                log_progress(f"âœ“ {ns} -> {lang}: {len(target_translations)} ä¸ªæ–°ç¿»è¯‘")
            else:
                log_progress(f"âœ— ä¿å­˜å¤±è´¥: {ns} -> {lang}", "error")

    log_progress(f"âœ“ æˆåŠŸä¿å­˜ {saved_count}/{len(all_translation_tasks)} ä¸ªç¿»è¯‘æ–‡ä»¶")

    log_section("æ™ºèƒ½ç¿»è¯‘å®Œæˆ")
    log_progress("ğŸ‰ æ‰€æœ‰å˜æ›´å·²å¤„ç†å®Œæˆï¼")
    perform_cleanup_extra_keys()
    log_section_end()


def main():
    """ä¸»å‡½æ•°"""
    log_section("ç¿»è¯‘è„šæœ¬å¯åŠ¨")

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        log_progress("é”™è¯¯ï¼šæœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡", "error")
        sys.exit(1)

    log_progress("âœ“ APIå¯†é’¥å·²é…ç½®")

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨éæ€è€ƒæ¨¡å¼
    non_thinking_mode = os.getenv('NON_THINKING_MODE', 'false').lower() == 'true'
    if non_thinking_mode:
        log_progress("âš¡ éæ€è€ƒæ¨¡å¼ï¼šä½¿ç”¨deepseek-chatæ¨¡å‹ä»¥æå‡é€Ÿåº¦")
    else:
        log_progress("ğŸ§  æ€è€ƒæ¨¡å¼ï¼šä½¿ç”¨deepseek-reasoneræ¨¡å‹ä»¥æå‡è´¨é‡")

    # åˆ›å»ºç¿»è¯‘å™¨
    translator = DeepSeekTranslator(api_key, non_thinking_mode)
    log_progress("âœ“ ç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆ")

    # æ£€æŸ¥ç¿»è¯‘æ¨¡å¼
    force_translate = os.getenv('FORCE_TRANSLATE', 'false').lower() == 'true'

    if force_translate:
        log_progress("ğŸ”„ å¼ºåˆ¶ç¿»è¯‘æ¨¡å¼ï¼šå°†é‡æ–°ç¿»è¯‘æ‰€æœ‰å†…å®¹ï¼ˆä½¿ç”¨åˆå¹¶ç¿»è¯‘é€»è¾‘ï¼‰")
        # ä½¿ç”¨å…¨é‡ç¿»è¯‘é€»è¾‘ï¼ˆå·²é›†æˆåˆå¹¶ç¿»è¯‘ï¼‰
        run_full_translation(translator)
    else:
        log_progress("ğŸ” æ™ºèƒ½ç¿»è¯‘æ¨¡å¼ï¼šæ£€æµ‹Gitå˜æ›´ï¼ˆä½¿ç”¨åˆå¹¶ç¿»è¯‘é€»è¾‘ï¼‰")
        # ä½¿ç”¨æ™ºèƒ½å·®å¼‚ç¿»è¯‘é€»è¾‘ï¼ˆå·²é›†æˆåˆå¹¶ç¿»è¯‘ï¼‰
        run_smart_translation(translator)